{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VK_publics_playground.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uazU_pB3elY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google_drive_downloader import GoogleDriveDownloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmyUskBuPydW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /tmp/*; wget -q https://gist.githubusercontent.com/Puzer/33c64edd7973a60f2040058a57ea1596/raw/078b2075e356ab9bb557733be80a6c0a82c47913/dataset.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zAA6ojlelY5",
        "colab_type": "text"
      },
      "source": [
        "# Loading already pre-trained publics embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPKY-Y8WQnbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset import *\n",
        "publics_emb, users_profile = load_data()\n",
        "publics_ids = set(publics_emb.index)\n",
        "\n",
        "publics_emb.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWAoWVf0elY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embeddings helper functions\n",
        "\n",
        "def get_publics_embedings(user_subscriptions):\n",
        "    idx = publics_emb.index.searchsorted(user_subscriptions)\n",
        "    return publics_emb.iloc[idx].sum(axis=0)\n",
        "\n",
        "def get_public_vector(public_id):\n",
        "    return publics_emb.loc[public_id].values.reshape((1, -1))\n",
        "\n",
        "def get_recommendations(vector, top_n=5, except_subscriptions={}):\n",
        "    r = cosine_similarity(publics_emb.values, vector)\n",
        "    indexes = publics_emb.iloc[r.argsort(axis=0)[::-1].reshape(-1)[:top_n]].index\n",
        "    indexes = [x for x in indexes if x not in except_subscriptions]\n",
        "    return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BABm3Rau5RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VK API helper functions\n",
        "# You can get your accsess_token using https://vkhost.github.io/\n",
        "# or official guidline https://vk.com/dev/access_token\n",
        "__ACCESS_TOKEN__ = '5a36e8db5a36e8db5a36e8db165a51cfb055a365a36e8db073056cebd7737a42f4e7ed1'\n",
        "\n",
        "def chunks(l, n):\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i+n]\n",
        "        \n",
        "def search_groups(ids):\n",
        "    if type(ids) is not list:\n",
        "        ids = [ids]\n",
        "    ids = list(map(str, ids))\n",
        "    result = list()\n",
        "    for r in chunks(ids, 400):\n",
        "        result.extend(search_groups_(r))\n",
        "    return result\n",
        "    \n",
        "def search_groups_(ids):\n",
        "    url='https://api.vk.com/method/groups.getById?fields=members_count&group_ids={0}&v=5.61&access_token={1}'.format(','.join(ids), __ACCESS_TOKEN__)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        json_result = response.json()\n",
        "        return json_result['response']\n",
        "    return None\n",
        "\n",
        "def get_public_id(public_url):\n",
        "    if isinstance(public_url, int) or public_url.isdigit():\n",
        "        return int(public_url)\n",
        "    else:\n",
        "        if 'public' in public_url:\n",
        "            public_url = public_url.replace('public','')\n",
        "        if '/' in public_url:\n",
        "            public_url = public_url.split('/')[3]\n",
        "        return search_groups_([public_url])[0]['id']\n",
        "\n",
        "def show_groups_info(responses):\n",
        "    for item in responses:\n",
        "        print('http://vk.com/public%d %s'%(item['id'], item['name']))\n",
        "\n",
        "def get_user_subscriptions(user_id):\n",
        "    url = 'https://api.vk.com/method/users.getSubscriptions?user_id={0}&v=5.63&access_token={1}'.format(user_id, __ACCESS_TOKEN__)\n",
        "    response = requests.get(url, timeout=30)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()['response']\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg4d6G9melZB",
        "colab_type": "text"
      },
      "source": [
        "# Measuring similarity between VK publics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "elf-DMREelZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_PUBLIC = 'https://vk.com/datascience'\n",
        "SHOW_TOP_N = 20\n",
        "\n",
        "# retrieving public ID from URL\n",
        "public_id = get_public_id(TEST_PUBLIC)\n",
        "\n",
        "# extracting already learned 128D vector (if TEST_PUBLIC in the index)\n",
        "public_vector = get_public_vector(public_id)\n",
        "\n",
        "# calculating similarity between TEST public and ALL others publics\n",
        "publics_similarity = cosine_similarity(publics_emb.values, public_vector) \n",
        "\n",
        "# sort ALL publics by similarity and take only TOP_N similar publics\n",
        "most_similar_indexes = publics_similarity.argsort(axis=0)[::-1].reshape(-1)[:SHOW_TOP_N]\n",
        "\n",
        "# take exact similarity values\n",
        "most_similar_values = publics_similarity[most_similar_indexes]\n",
        "\n",
        "# convert internal indexes into VK indexes\n",
        "most_similar_publics_ids = publics_emb.iloc[most_similar_indexes].index\n",
        "\n",
        "# retrieval public information (like public name)\n",
        "most_similar_publics_info = search_groups(most_similar_publics_ids.tolist())\n",
        "\n",
        "\n",
        "# show most similar publics\n",
        "for public_info, public_similarity in zip(most_similar_publics_info, most_similar_values):\n",
        "    print('[%f] https://vk.com/public%d %s'%(public_similarity, public_info['id'], public_info['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH-b_KrEelZE",
        "colab_type": "text"
      },
      "source": [
        "# Making recommendations for a user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GbyJ_CVelZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_USER_ID = 16184332\n",
        "\n",
        "# retrieving test user subscriptions (publics)\n",
        "user_subscriptions_ids = get_user_subscriptions(TEST_USER_ID)['groups']['items']\n",
        "\n",
        "# filter publics by checking if the public is already learned\n",
        "user_subscriptions_ids = list(filter(lambda x: x in publics_ids, user_subscriptions_ids))\n",
        "user_subscriptions_name = [x['name'] for x in search_groups(user_subscriptions_ids)]\n",
        "\n",
        "if len(user_subscriptions_ids) == 0:\n",
        "    raise Exception(\"There are no subsriptions\")\n",
        "\n",
        "# extracting vectors for all user subscriptions (publics)\n",
        "user_subscriptions_embeddings = np.vstack([get_public_vector(x) for x in user_subscriptions_ids])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCrlEHFGelZK",
        "colab_type": "text"
      },
      "source": [
        "### Calculating closest publics to the user's vector representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAJfUM9LelZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting *user vector* by summing all embeddings\n",
        "user_representation = np.sum(user_subscriptions_embeddings, axis=0).reshape(1, -1)\n",
        "\n",
        "# the same steps as in previous\n",
        "# calculating similarity between TEST public and ALL others publics\n",
        "publics_similarity = cosine_similarity(publics_emb.values, user_representation) \n",
        "\n",
        "# sort ALL publics by similarity and take only TOP_N similar publics\n",
        "most_similar_indexes = publics_similarity.argsort(axis=0)[::-1].reshape(-1)[:SHOW_TOP_N]\n",
        "\n",
        "# take exact similarity values\n",
        "most_similar_values = publics_similarity[most_similar_indexes]\n",
        "\n",
        "# convert internal indexes into VK indexes\n",
        "most_similar_publics_ids = publics_emb.iloc[most_similar_indexes].index\n",
        "\n",
        "# retrieval public information (like public name)\n",
        "most_similar_publics_info = search_groups(most_similar_publics_ids.tolist())\n",
        "\n",
        "\n",
        "# show most similar publics\n",
        "for public_info, public_similarity in zip(most_similar_publics_info, most_similar_values):\n",
        "    print('[%f] https://vk.com/public%d %s'%(public_similarity, public_info['id'], public_info['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J5GK6Q8elZO",
        "colab_type": "text"
      },
      "source": [
        "# Visualization of semantic space for top 10000 VK publics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_h9VZDselZP",
        "colab_type": "text"
      },
      "source": [
        "Visualization of semantic space for top 10000 VK publics <br>\n",
        "https://puzer.github.io/projector/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vREjMtp9elZP",
        "colab_type": "text"
      },
      "source": [
        "# Predicting user gender based on subscriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3HpYyVGelZQ",
        "colab_type": "text"
      },
      "source": [
        "### Loading a random sample of users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qrt20pDelZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Users in sample:', len(users_profile))\n",
        "print('One example:')\n",
        "next(iter(users_profile.values()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t-kGWOselZT",
        "colab_type": "text"
      },
      "source": [
        "### EDA (exploratory data analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjCapTFlelZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist([len(v['subscriptions']) for k,v in users_profile.items() if v['sex']==1], bins=50, label='female', alpha=0.5)\n",
        "plt.hist([len(v['subscriptions']) for k,v in users_profile.items() if v['sex']==2], bins=50, label='male', alpha=0.5)\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Distribution of subscriptions')\n",
        "plt.xlabel('Number of subscriptions')\n",
        "plt.ylabel('Number of people')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUFEOKh2elZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist([v['date'] for k,v in users_profile.items() if v['sex']==1], bins=50, label='female', alpha=0.5)\n",
        "plt.hist([v['date'] for k,v in users_profile.items() if v['sex']==2], bins=50, label='male', alpha=0.5)\n",
        "\n",
        "plt.title('Distribution of age in the sample')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of people')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m5hJrblelZZ",
        "colab_type": "text"
      },
      "source": [
        "### Most popular publics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9dI6QhlelZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "from collections import Counter\n",
        "\n",
        "all_subscriptions = list(chain(*[v['subscriptions'] for k,v in users_profile.items()]))\n",
        "publics_frequency = Counter(all_subscriptions)\n",
        "\n",
        "show_groups_info(search_groups(list(list(zip(*publics_frequency.most_common(10)))[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC7uJot3elZf",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFCY5gJrelZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "target = list()\n",
        "users_subscriptions = list()\n",
        "\n",
        "for k,v in users_profile.items():\n",
        "    user_publics = publics_ids & set( v['subscriptions'])\n",
        "    if len(user_publics) >= 5:\n",
        "        target.append(v['sex'] == 2) # is it a male ?\n",
        "        users_subscriptions.append({uid:1 for uid in user_publics})\n",
        "\n",
        "dict_vectorizer = DictVectorizer()\n",
        "X_data = dict_vectorizer.fit_transform(users_subscriptions)\n",
        "dict_vectorizer.inverse_vocabulary_ = {v:k for k,v in dict_vectorizer.vocabulary_.items()}\n",
        "\n",
        "y_data = np.array(target)\n",
        "\n",
        "X_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWLbN2iTelZm",
        "colab_type": "text"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFxIJ17zelZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=42)\n",
        "\n",
        "clf = SGDClassifier(loss='log', penalty = 'l2', class_weight='balanced', max_iter=5)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blfIymkwelZr",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z78-hpyqelZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy:', clf.score(X_test, y_test))\n",
        "print('AUC-ROC:', roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nh3paQFelZy",
        "colab_type": "text"
      },
      "source": [
        "### Analysing of model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9-2jXqEelZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_of_subscriptions = X_test.sum(axis=1).A.reshape(-1)\n",
        "\n",
        "thresholds = list(range(5, 100, 5))\n",
        "accuracy_scores = list()\n",
        "\n",
        "for nb_of_subscriptions_threshold in thresholds:\n",
        "    mask = nb_of_subscriptions >= nb_of_subscriptions_threshold\n",
        "    accuracy_scores.append(clf.score(X_test[mask], y_test[mask]))\n",
        "    \n",
        "plt.plot(thresholds, accuracy_scores)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of subscriptions')\n",
        "plt.title('Influence of number of subscriptions on accuracy')\n",
        "plt.xticks(thresholds)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMAkaN68ni5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_slices = np.linspace(100, X_train.shape[0], 100).astype('int32')\n",
        "\n",
        "scores = list()\n",
        "for x_slice in tqdm_notebook(dataset_slices):\n",
        "  clf = SGDClassifier(loss='log', penalty = 'l2', class_weight='balanced', max_iter=5)\n",
        "  clf.fit(X_train[:x_slice], y_train[:x_slice])\n",
        "  scores.append(clf.score(X_test, y_test))\n",
        "  \n",
        "plt.plot(dataset_slices, scores)\n",
        "plt.title('Influence of number of training data on accuracy \\n for a linear model trained on sparse data')\n",
        "plt.xlabel('Number of training points (log)')\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSKKpudQelZ1",
        "colab_type": "text"
      },
      "source": [
        "### Analysing model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "34FXAf_4elZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_params_args = clf.coef_[0].argsort()\n",
        "\n",
        "most_feminine_publics = [dict_vectorizer.inverse_vocabulary_[x] for x in model_params_args[:10]]\n",
        "most_masculine_publics =  [dict_vectorizer.inverse_vocabulary_[x] for x in model_params_args[-10:]]\n",
        "\n",
        "print('The most masculine publics')\n",
        "show_groups_info(search_groups(most_masculine_publics))\n",
        "\n",
        "print('\\n\\nThe most feminine publics')\n",
        "show_groups_info(search_groups(most_feminine_publics))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1OudifFelZ6",
        "colab_type": "text"
      },
      "source": [
        "# Training model using pretrained publics embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78flOo-BelZ6",
        "colab_type": "text"
      },
      "source": [
        "### on limited number of training examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rolI759MelZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users_vectors = list()\n",
        "for subscr in tqdm_notebook(users_subscriptions):\n",
        "    user_embedding = get_publics_embedings(list(subscr.keys()))\n",
        "    users_vectors.append(user_embedding)\n",
        "    \n",
        "users_vectors = np.array(users_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MKg4U1gelZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(users_vectors, y_data, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(penalty = 'l2', class_weight='balanced', solver='lbfgs')\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EXQtiBukf2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy:', clf.score(X_test, y_test))\n",
        "print('AUC-ROC:', roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWzcnls7qn6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_slices = np.linspace(100, X_train.shape[0], 100).astype('int32')\n",
        "\n",
        "scores = list()\n",
        "for x_slice in tqdm_notebook(dataset_slices):\n",
        "  clf = LogisticRegression(penalty = 'l2', class_weight='balanced', solver='lbfgs')\n",
        "  clf.fit(X_train[:x_slice], y_train[:x_slice])\n",
        "  scores.append(clf.score(X_test, y_test))\n",
        "  \n",
        "plt.plot(dataset_slices, scores)\n",
        "plt.title('Influence of number of training data on accuracy \\n for a linear model trained on pre-trained embeddings')\n",
        "plt.xlabel('Number of training points (log)')\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}